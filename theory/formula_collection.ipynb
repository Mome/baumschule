{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HyperParameter Optimization + Model Selection\n",
    "---------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "** Hyperparameter Optimization (Bergstra, Bengio):**\n",
    "\n",
    "$$ \\lambda^{(*)} = \\underset{\\lambda \\in \\Lambda}{\\operatorname{argmin}} \\mathbb{E}_{x\\tilde{}\\mathcal{G}_x}\\big[\\mathcal{L}\\big(x;\\mathcal{A}_\\lambda(X_{train})\\big)\\big] $$\n",
    "\n",
    "||\n",
    "|-|\n",
    "|$\\mathcal{L}$|loss function\n",
    "|$\\mathcal{A}_\\lambda$|learning algorithm\n",
    "|$\\mathcal{G}_x$| sample distribution\n",
    "|$\\Psi$|hyper-parameter response function / surface\n",
    "|$\\Lambda_s$| evaluated hyper-parameter configurations\n",
    "\n",
    "$$ \\lambda^{(*)} \\approx \\underset{\\lambda \\in \\Lambda}{\\operatorname{argmin}} \\sum_{x \\in X_{val}}\\mathcal{L}\\big(x;\\mathcal{A}_\\lambda(X_{train})\\big)$$\n",
    "\n",
    "$$ = \\underset{\\lambda \\in \\Lambda}{\\operatorname{argmin}} \\Psi(\\lambda) \n",
    "\\approx \\underset{\\lambda \\in \\Lambda_s}{\\operatorname{argmin}} \\Psi(\\lambda) = \\hat{\\lambda}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization Aspects\n",
    "--------------------\n",
    "\n",
    "* litmited recources\n",
    "* parrallel evaluation required?\n",
    "* gradient available?\n",
    "\n",
    "**Loss-Function:**\n",
    "- stochastic\n",
    "- assumption: close parameters configuration have close loss\n",
    "- expensive to evaluate\n",
    "\n",
    "**Parameter-Space:**\n",
    " - real-valued / integres / categories\n",
    " - finite / infinite\n",
    " - bounded / unbounded\n",
    " - vector / tree-structure / graph-structure\n",
    " \n",
    "Algorithms\n",
    "---\n",
    "\n",
    "**model-based** - construct a regression model (often called a *response surface model*) that predicts performance\n",
    "\n",
    "**sequential model-based optimization** - (SMBO) iterates between fitting a model and gathering additional data based on this model\n",
    " - Gaussian Process Models are the most common choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Grid Search**\n",
    "\n",
    "Choose a set of values $L_i$ for each variabel $\\lambda_i$.\n",
    "\n",
    "$\\Lambda_s = L_1\\times\\dots\\times L_k$\n",
    "\n",
    "$s = |\\Lambda| = \\prod_{i=0}^k |L_i|$\n",
    "\n",
    "**Combined Manual & Grid Search:** first look for promising reagions, than apply Grid Search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Bergstra, J., & Bengio, Y. (2012). **Random search for hyper-parameter optimization.**\n",
    "\n",
    " - Random search has all the practical advantages of grid search (conceptual simplicity, ease of implementation,\n",
    "trivial parallelism) and trades a small reduction in efficiency in low-dimensional spaces for a large\n",
    "improvement in efficiency in high-dimensional search spaces.\n",
    "In this work we show that random search is more efficient than grid search in high-dimensional\n",
    " - random search works much better for low effective dimensionality: $ f(x,y) \\approx g(x) $\n",
    "\n",
    "<img src=\"random_vs_grid_layout.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------\n",
    "Sequential Model-based Global Optimization (SMBO)\n",
    "------------------------------------------\n",
    "\n",
    "||\n",
    "|-|\n",
    "|$f$|fitness function / surrogate\n",
    "|$M_t$| model\n",
    "|$T$| iterations\n",
    "|$S$|\n",
    "|$\\mathcal{H}$|observation history\n",
    "\n",
    "<img src=\"smbo.png\"></img>\n",
    "<img src=\"smbo_graph.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Shahriari, Bobak, et al. **Taking the human out of the loop: A review of bayesian optimization** (2016)\n",
    "\n",
    "<img src=\"bayesian_optimization.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Expected Improvement\n",
    "* Probability of Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some Python Modules\n",
    "--------------------------\n",
    "\n",
    "* **scipy.optimize** - many different optimizers, probably not suitable for hyperparameters\n",
    "* **hyperopt**\n",
    "  * Random Search\n",
    "  * Tree of Parzen Estimators (TPE)\n",
    "* **autosklearn** - automated machine learning toolkit\n",
    "* **sacred** - record machine learning experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efficient and Robust Automated Machine Learning\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**General Setting of the Learning Problem (Vapnik):**\n",
    "\n",
    "$$ R(\\alpha) = \\int Q(z,\\alpha)dP(z) $$\n",
    "$$ R_{emp}(\\alpha)=\\frac{1}{\\mathscr{l}}\\sum_{i=1}^\\mathscr{l}Q(z_i,\\alpha)$$\n",
    "\n",
    "ERM principle - empirical risk mimization inductive principle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "**Close Parameter Configurations have Close Loss:**\n",
    " \n",
    "if $|\\varepsilon|<|\\delta|$ and\n",
    "$$ d_\\varepsilon = \\big|R(x) - R(x + \\varepsilon)\\big| $$\n",
    "$$ d_\\delta = \\big|R(x) - R(x + \\delta)\\big|$$ then\n",
    "$$ P\\big(d_\\varepsilon < d_\\delta\\big) > P\\big(d_\\varepsilon > d_\\delta\\big)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Bayesian Linear Regression\n",
    "--------------------------\n",
    "\n",
    "$\n",
    "y=f(x)+\\varepsilon\n",
    "\\ \\ \\ \\ \\ \\ \n",
    "f(x)=\\phi(x)^\\top w\n",
    "\\ \\ \\ \\ \\ \\ \n",
    "\\varepsilon \\sim \\mathcal{N}(0,\\sigma^2_n)\n",
    "$\n",
    "\n",
    "$f_* \\big\\rvert \\ \\pmb{x}_*,X,\\pmb{y} \\sim \\mathcal{N}\\big(\\phi_*^\\top\\Sigma_p\\Phi(K+\\sigma^2_nI)^{-1}\\big) $\n",
    "\n",
    "||\n",
    "|-|\n",
    "|$f$|target function|\n",
    "|$f_*$|a\n",
    "|$X$|a\n",
    "|$X_*$|a\n",
    "\n",
    "\n",
    "Gaussian Processes for Regression\n",
    "---------------------------------\n",
    "\n",
    "$m(x) = \\mathbb{E}\\big[f(x)\\big]$\n",
    "\n",
    "$k(x,x') = \\mathbb{E}\\big[(f(x)-m(x))(f(x')-m(x'))\\big]$\n",
    "\n",
    "$f(x) \\sim \\mathcal{GP}\\big(m(x),k(x,x')\\big)$\n",
    "\n",
    "$f_* \\sim \\mathcal{N}\\big(0,K(X_*,X_*)\\big)$\n",
    "\n",
    "\n",
    "Prediction with Noise-Free Observations\n",
    "---------------------\n",
    "$\\begin{bmatrix}\n",
    "\\mathrm{\\pmb{f}}_{\\ } \\\\\n",
    "\\mathrm{\\pmb{f}}_*  \\\\ \\end{bmatrix}\n",
    "\\sim \\mathcal{N}\\bigg(\\pmb{0},\n",
    "\\begin{bmatrix}\n",
    "K(X,X) & K(X,X_*) \\\\\n",
    "K(X_*,X) & K(X_*,X_*)\\\\ \\end{bmatrix}\n",
    "\\bigg) $\n",
    "\n",
    "Prediction with Noisy Observations\n",
    "---------------------\n",
    "$\\begin{bmatrix}\n",
    "\\mathrm{\\pmb{f}}_{\\ } \\\\\n",
    "\\mathrm{\\pmb{f}}_*  \\\\ \\end{bmatrix}\n",
    "\\sim \\mathcal{N}\\bigg(\\pmb{0},\n",
    "\\begin{bmatrix}\n",
    "K(X,X) + \\sigma^2_n I& K(X,X_*) \\\\\n",
    "K(X_*,X) & K(X_*,X_*)\\\\ \\end{bmatrix}\n",
    "\\bigg) $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
