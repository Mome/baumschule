
@inproceedings{bartz-beielstein_sequential_2009,
	title = {Sequential parameter optimization},
	url = {http://drops.dagstuhl.de/opus/volltexte/2009/2115/},
	booktitle = {Dagstuhl Seminar Proceedings},
	publisher = {Schloss Dagstuhl-Leibniz-Zentrum für Informatik},
	author = {Bartz-Beielstein, Thomas},
	urldate = {2016-07-06},
	date = {2009}
}

@incollection{bartz-beielstein_sequential_2010,
	location = {Berlin, Heidelberg},
	title = {Sequential Model-Based Parameter Optimization: an Experimental Investigation of Automated and Interactive Approaches},
	isbn = {978-3-642-02537-2 978-3-642-02538-9},
	url = {http://link.springer.com/10.1007/978-3-642-02538-9_15},
	shorttitle = {Sequential Model-Based Parameter Optimization},
	pages = {363--414},
	booktitle = {Experimental Methods for the Analysis of Optimization Algorithms},
	publisher = {Springer Berlin Heidelberg},
	author = {Hutter, Frank and Bartz-Beielstein, Thomas and Hoos, Holger H. and Leyton-Brown, Kevin and Murphy, Kevin P.},
	editor = {Bartz-Beielstein, Thomas and Chiarandini, Marco and Paquete, Luís and Preuss, Mike},
	urldate = {2016-07-07},
	date = {2010},
	langid = {english}
}

@article{sacks_design_1989,
	title = {Design and Analysis of Computer Experiments},
	url = {http://www.stat.osu.edu/~comp_exp/jour.club/Sacks89.pdf},
	author = {Sacks, Jerome and Welch, William J. and Mitchell, Toby J. and Wynn, Henry P.},
	urldate = {2016-07-07},
	date = {1989-11}
}

@inproceedings{zheng_lazy_2013,
	title = {Lazy Paired Hyper-Parameter Tuning.},
	url = {http://www.ijcai.org/Proceedings/13/Papers/284.pdf},
	booktitle = {{IJCAI}},
	author = {Zheng, Alice X. and Bilenko, Mikhail},
	urldate = {2016-06-30},
	date = {2013}
}

@article{greff_introducing_????,
	title = {Introducing Sacred: A Tool to Facilitate Reproducible Research},
	url = {https://indico.lal.in2p3.fr/event/2914/session/0/contribution/1/1/material/paper/0.pdf},
	shorttitle = {Introducing Sacred},
	author = {Greff, Klaus and Schmidhuber, Jürgen},
	urldate = {2016-07-11}
}

@article{li_efficient_2016,
	title = {Efficient Hyperparameter Optimization and Infinitely Many Armed Bandits},
	url = {http://arxiv.org/abs/1603.06560},
	journaltitle = {{arXiv} preprint {arXiv}:1603.06560},
	author = {Li, Lisha and Jamieson, Kevin and {DeSalvo}, Giulia and Rostamizadeh, Afshin and Talwalkar, Ameet},
	urldate = {2016-06-20},
	date = {2016}
}

@incollection{hutter_time-bounded_2010,
	title = {Time-bounded sequential parameter optimization},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-13800-3_30},
	pages = {281--298},
	booktitle = {Learning and intelligent optimization},
	publisher = {Springer},
	author = {Hutter, Frank and Hoos, Holger H. and Leyton-Brown, Kevin and Murphy, Kevin},
	urldate = {2016-05-16},
	date = {2010}
}

@inproceedings{bartz-beielstein_sequential_2005,
	title = {Sequential parameter optimization},
	volume = {1},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1554761},
	pages = {773--780},
	booktitle = {2005 {IEEE} congress on evolutionary computation},
	publisher = {{IEEE}},
	author = {Bartz-Beielstein, Thomas and Lasarczyk, Christian {WG} and Preu\{{\textbackslash}textbackslash\}s s, Mike},
	urldate = {2016-07-06},
	date = {2005}
}

@inproceedings{feurer_initializing_2015,
	title = {Initializing Bayesian Hyperparameter Optimization via Meta-Learning.},
	url = {https://pdfs.semanticscholar.org/9be7/e7579fbec5d45e3e6ea1c4465258225a183d.pdf},
	pages = {1128--1135},
	booktitle = {{AAAI}},
	author = {Feurer, Matthias and Springenberg, Jost Tobias and Hutter, Frank},
	urldate = {2016-06-30},
	date = {2015}
}

@article{pelikan_survey_2002,
	title = {A survey of optimization by building and using probabilistic models},
	volume = {21},
	url = {http://link.springer.com/article/10.1023/A:1013500812258},
	pages = {5--20},
	number = {1},
	journaltitle = {Computational optimization and applications},
	author = {Pelikan, Martin and Goldberg, David E. and Lobo, Fernando G.},
	urldate = {2016-07-08},
	date = {2002}
}

@article{fernandez-delgado_we_2014,
	title = {Do we need hundreds of classifiers to solve real world classification problems?},
	volume = {15},
	url = {http://dl.acm.org/citation.cfm?id=2697065},
	pages = {3133--3181},
	number = {1},
	journaltitle = {The Journal of Machine Learning Research},
	author = {Fernández-Delgado, Manuel and Cernadas, Eva and Barro, Senén and Amorim, Dinani},
	urldate = {2016-01-31},
	date = {2014}
}

@inproceedings{lokuciejewski_automatic_2010,
	title = {Automatic Selection of Machine Learning Models for Compiler Heuristic Generation},
	url = {http://ctuning.org/dissemination/smart10-proceedings.pdf#page=4},
	booktitle = {Proceedings of the 4th Workshop on Statistical and Machine Learning Approaches to {ARchitecture} und {compilaTion} {SMART}},
	author = {Lokuciejewski, Paul and Stolpe, Marco and Morik, Katharina and Marwedel, Peter},
	urldate = {2016-02-23},
	date = {2010}
}

@inproceedings{pelikan_boa:_1999,
	title = {{BOA}: The Bayesian optimization algorithm},
	url = {http://dl.acm.org/citation.cfm?id=2933973},
	shorttitle = {{BOA}},
	pages = {525--532},
	booktitle = {Proceedings of the 1st Annual Conference on Genetic and Evolutionary Computation-Volume 1},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Pelikan, Martin and Goldberg, David E. and Cantú-Paz, Erick},
	urldate = {2016-07-08},
	date = {1999}
}

@article{gelbart_bayesian_2014,
	title = {Bayesian optimization with unknown constraints},
	url = {http://arxiv.org/abs/1403.5607},
	journaltitle = {{arXiv} preprint {arXiv}:1403.5607},
	author = {Gelbart, Michael A. and Snoek, Jasper and Adams, Ryan P.},
	urldate = {2016-06-24},
	date = {2014}
}

@article{austerweil_structure_2015,
	title = {Structure and flexibility in bayesian models of cognition},
	url = {https://books.google.de/books?hl=de&lr=&id=_dbFBgAAQBAJ&oi=fnd&pg=PA187&ots=-kyhy6KEU_&sig=naKuEZjKzHMtqH7ODpSp82ylYzY},
	pages = {187--208},
	journaltitle = {Oxford handbook of computational and mathematical psychology},
	author = {Austerweil, Joseph L. and Gershman, Samuel J. and Tenenbaum, Joshua B. and Griffiths, Thomas L.},
	urldate = {2016-02-23},
	date = {2015},
	file = {Snapshot:/home/student/m/mmeier/.mozilla/firefox/zg92muzl.default-1472461511945/zotero/storage/JEEW5DZ6/books.html:text/html}
}

@incollection{hutter_sequential_2011,
	title = {Sequential model-based optimization for general algorithm configuration},
	url = {http://link.springer.com/10.1007%2F978-3-642-25566-3_40},
	pages = {507--523},
	booktitle = {Learning and Intelligent Optimization},
	publisher = {Springer},
	author = {Hutter, Frank and Hoos, Holger H. and Leyton-Brown, Kevin},
	urldate = {2016-04-16},
	date = {2011}
}

@article{hernandez-lobato_general_2015,
	title = {A General Framework for Constrained Bayesian Optimization using Information-based Search},
	url = {http://arxiv.org/abs/1511.09422},
	journaltitle = {{arXiv} preprint {arXiv}:1511.09422},
	author = {Hernández-Lobato, José Miguel and Gelbart, Michael A. and Adams, Ryan P. and Hoffman, Matthew W. and Ghahramani, Zoubin},
	urldate = {2016-07-08},
	date = {2015}
}

@inproceedings{bergstra_hyperopt:_2013,
	title = {Hyperopt: A python library for optimizing the hyperparameters of machine learning algorithms},
	url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.704.3494&rep=rep1&type=pdf},
	shorttitle = {Hyperopt},
	pages = {13--20},
	booktitle = {Proceedings of the 12th Python in Science Conference},
	publisher = {Citeseer},
	author = {Bergstra, James and Yamins, Dan and Cox, David D.},
	urldate = {2016-07-23},
	date = {2013}
}

@inproceedings{eggensperger_towards_2013,
	title = {Towards an empirical foundation for assessing bayesian optimization of hyperparameters},
	url = {https://www.cs.ubc.ca/~hoos/Publ/EggEtAl13.pdf},
	booktitle = {{NIPS} workshop on Bayesian Optimization in Theory and Practice},
	author = {Eggensperger, Katharina and Feurer, Matthias and Hutter, Frank and Bergstra, James and Snoek, Jasper and Hoos, Holger and Leyton-Brown, Kevin},
	urldate = {2016-05-16},
	date = {2013}
}

@inproceedings{gardner_bayesian_2014,
	title = {Bayesian Optimization with Inequality Constraints.},
	url = {http://www.jmlr.org/proceedings/papers/v32/gardner14.pdf},
	pages = {937--945},
	booktitle = {{ICML}},
	author = {Gardner, Jacob R. and Kusner, Matt J. and Xu, Zhixiang Eddie and Weinberger, Kilian Q. and Cunningham, John},
	urldate = {2016-06-24},
	date = {2014}
}

@incollection{hutter_parallel_2012,
	title = {Parallel algorithm configuration},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-34413-8_5},
	pages = {55--70},
	booktitle = {Learning and Intelligent Optimization},
	publisher = {Springer},
	author = {Hutter, Frank and Hoos, Holger H. and Leyton-Brown, Kevin},
	urldate = {2016-05-16},
	date = {2012}
}

@article{hutter_bayesian_2013,
	title = {Bayesian optimization with censored response data},
	url = {http://arxiv.org/abs/1310.1947},
	journaltitle = {{arXiv} preprint {arXiv}:1310.1947},
	author = {Hutter, Frank and Hoos, Holger and Leyton-Brown, Kevin},
	urldate = {2016-06-30},
	date = {2013}
}

@inproceedings{thornton_auto-weka:_2013,
	title = {Auto-{WEKA}: Combined selection and hyperparameter optimization of classification algorithms},
	url = {http://dl.acm.org/citation.cfm?id=2487629},
	shorttitle = {Auto-{WEKA}},
	pages = {847--855},
	booktitle = {Proceedings of the 19th {ACM} {SIGKDD} international conference on Knowledge discovery and data mining},
	publisher = {{ACM}},
	author = {Thornton, Chris and Hutter, Frank and Hoos, Holger H. and Leyton-Brown, Kevin},
	urldate = {2016-01-18},
	date = {2013}
}

@incollection{bergstra_algorithms_2011,
	title = {Algorithms for Hyper-Parameter Optimization},
	url = {http://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf},
	pages = {2546--2554},
	booktitle = {Advances in Neural Information Processing Systems 24},
	publisher = {Curran Associates, Inc.},
	author = {Bergstra, James S. and Bardenet, Rémi and Bengio, Yoshua and Kégl, Balázs},
	editor = {Shawe-Taylor, J. and Zemel, R. S. and Bartlett, P. L. and Pereira, F. and Weinberger, K. Q.},
	urldate = {2016-04-16},
	date = {2011},
	keywords = {hyperparamter},
	file = {NIPS Snapshort:/home/student/m/mmeier/.mozilla/firefox/zg92muzl.default-1472461511945/zotero/storage/ZN4IPTTD/4443-algorithms-for-hyper-parameter-optimization.html:text/html}
}

@inproceedings{wistuba_learning_2015,
	title = {Learning hyperparameter optimization initializations},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7344817},
	pages = {1--10},
	booktitle = {Data Science and Advanced Analytics ({DSAA}), 2015. 36678 2015. {IEEE} International Conference on},
	publisher = {{IEEE}},
	author = {Wistuba, Martin and Schilling, Nicolas and Schmidt-Thieme, Lars},
	urldate = {2016-01-31},
	date = {2015}
}

@inproceedings{hoffman_portfolio_2011,
	title = {Portfolio Allocation for Bayesian Optimization.},
	url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.406.7117&rep=rep1&type=pdf},
	pages = {327--336},
	booktitle = {{UAI}},
	publisher = {Citeseer},
	author = {Hoffman, Matthew D. and Brochu, Eric and de Freitas, Nando},
	urldate = {2016-05-16},
	date = {2011}
}

@thesis{hutter_automated_2009,
	title = {Automated configuration of algorithms for solving hard computational problems},
	url = {https://open.library.ubc.ca/handle/bitstream/34023/1/UBC_1971_A6%20M38.pdf},
	type = {phdthesis},
	author = {Hutter, Frank},
	urldate = {2016-05-16},
	date = {2009}
}

@article{meinel_hyperparameter_2016,
	title = {Hyperparameter Optimization for Machine Learning Problems in {BCI}},
	url = {http://aad.informatik.uni-freiburg.de/papers/16-BCIMeeting-HypOpt.pdf},
	author = {Meinel, A. and Eggensperger, K. and Tangermann, M. and Hutter, F.},
	urldate = {2016-06-23},
	date = {2016}
}

@online{_contest_2016,
	title = {Contest 2nd Place: Automating Data Science},
	url = {http://www.kdnuggets.com/2016/08/automating-data-science.html},
	shorttitle = {Contest 2nd Place},
	urldate = {2016-08-08},
	date = {2016-08},
	file = {Snapshot:/home/student/m/mmeier/.mozilla/firefox/zg92muzl.default-1472461511945/zotero/storage/G8ZDCSTV/automating-data-science.html:text/html}
}

@online{thakur_approaching_2016,
	title = {Approaching (Almost) Any Machine Learning Problem},
	url = {http://blog.kaggle.com/2016/07/21/approaching-almost-any-machine-learning-problem-abhishek-thakur/},
	abstract = {An average data scientist deals with loads of data daily. Some say over 60-70\% time is spent in data cleaning, munging and bringing data to a suitable format such that machine learning models can b…},
	titleaddon = {No Free Hunch},
	author = {Thakur, Abhishek},
	urldate = {2016-08-19},
	date = {2016-07-21}
}

@article{schaul_metalearning_2010,
	title = {Metalearning},
	volume = {5},
	issn = {1941-6016},
	url = {http://www.scholarpedia.org/article/Metalearning},
	doi = {10.4249/scholarpedia.4650},
	pages = {4650},
	number = {6},
	journaltitle = {Scholarpedia},
	author = {Schaul, Tom and Schmidhuber, Juergen},
	urldate = {2016-05-16},
	date = {2010},
	langid = {english}
}

@article{thornton_auto-weka:_2012,
	title = {Auto-{WEKA}: Automated selection and hyper-parameter optimization of classification algorithms},
	url = {https://www.researchgate.net/profile/Holger_Hoos/publication/230700205_Auto-WEKA_Combined_Selection_and_Hyperparameter_Optimization_ofClassification_Algorithms/links/0fcfd512a48fc9ceb8000000.pdf},
	shorttitle = {Auto-{WEKA}},
	journaltitle = {{CoRR}, abs/1208.3719},
	author = {Thornton, Chris and Hutter, Frank and Hoos, Holger H. and Leyton-Brown, Kevin},
	urldate = {2016-06-07},
	date = {2012}
}

@inproceedings{domhan_speeding_2015,
	title = {Speeding up automatic hyperparameter optimization of deep neural networks by extrapolation of learning curves},
	url = {https://pdfs.semanticscholar.org/044f/0b1d5d0b421abbc7569ba4cc4bf859fd9801.pdf},
	booktitle = {Proceedings of the 24th International Joint Conference on Artificial Intelligence ({IJCAI})},
	author = {Domhan, Tobias and Springenberg, Jost Tobias and Hutter, Frank},
	urldate = {2016-06-30},
	date = {2015}
}

@inproceedings{eggensperger_surrogate_2014,
	title = {Surrogate Benchmarks for Hyperparameter Optimization.},
	url = {http://ceur-ws.org/Vol-1201/MetaSel2014-complete.pdf#page=29},
	pages = {24--31},
	booktitle = {{MetaSel}@ {ECAI}},
	author = {Eggensperger, Katharina and Hutter, Frank and Hoos, Holger H. and Leyton-Brown, Kevin},
	urldate = {2016-06-30},
	date = {2014}
}

@article{brochu_tutorial_2010,
	title = {A tutorial on Bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning},
	url = {http://arxiv.org/abs/1012.2599},
	journaltitle = {{arXiv} preprint {arXiv}:1012.2599},
	author = {Brochu, Eric and Cora, Vlad M. and De Freitas, Nando},
	urldate = {2016-05-16},
	date = {2010},
	file = {Snapshot:/home/student/m/mmeier/.mozilla/firefox/zg92muzl.default-1472461511945/zotero/storage/3Z2GN9QD/1012.html:text/html}
}

@inproceedings{hutter_automatic_2007,
	title = {Automatic Algorithm Configuration based on Local Search},
	abstract = {The determination of appropriate values for free algorithm parameters is a challenging and tedious task in the design of effective algorithms for hard problems. Such parameters include categorical choices (e.g., neighborhood structure in local search or variable/value ordering heuristics in tree search), as well as numerical parameters (e.g., noise or restart timing). In practice, tuning of these parameters is largely carried out manually by applying rules of thumb and crude heuristics, while more principled approaches are only rarely used. In this paper, we present a local search approach for algorithm configuration and prove its convergence to the globally optimal parameter configuration. Our approach is very versatile: it can, e.g., be used for minimising run-time in decision problems or for maximising solution quality in optimisation problems. It further applies to arbitrary algorithms, including heuristic tree search and local search algorithms, with no limitation on the number of parameters. Experiments in four algorithm configuration scenarios demonstrate that our automatically determined parameter settings always outperform the algorithm defaults, sometimes by several orders of magnitude. Our approach also shows better performance and greater flexibility than the recent {CALIBRA} system. Our {ParamILS} code, along with instructions on how to use it for tuning your own algorithms, is available on-line at},
	pages = {1152--1157},
	booktitle = {{IN} {AAAI} ’07: {PROC}. {OF} {THE} {TWENTY}-{SECOND} {CONFERENCE} {ON} {ARTIFICAL} {IN}℡{LIGENCE}},
	author = {Hutter, Frank and Hoos, Holger H. and Stützle, Thomas},
	date = {2007},
	file = {Citeseer - Snapshot:/home/student/m/mmeier/.mozilla/firefox/zg92muzl.default-1472461511945/zotero/storage/3HUF69T2/summary.html:text/html}
}

@inproceedings{kraska_mlbase:_2013,
	title = {{MLbase}: A Distributed Machine-learning System.},
	volume = {1},
	url = {http://cidrdb.org/cidr2013/Papers/CIDR13_Paper118.pdf},
	shorttitle = {{MLbase}},
	pages = {2--1},
	booktitle = {{CIDR}},
	author = {Kraska, Tim and Talwalkar, Ameet and Duchi, John C. and Griffith, Rean and Franklin, Michael J. and Jordan, Michael I.},
	urldate = {2016-06-09},
	date = {2013}
}

@article{shahriari_taking_2016,
	title = {Taking the Human Out of the Loop: A Review of Bayesian Optimization},
	volume = {104},
	issn = {0018-9219},
	doi = {10.1109/JPROC.2015.2494218},
	shorttitle = {Taking the Human Out of the Loop},
	abstract = {Big Data applications are typically associated with systems involving large numbers of users, massive complex software systems, and large-scale heterogeneous computing and storage architectures. The construction of such systems involves many distributed design choices. The end products (e.g., recommendation systems, medical analysis tools, real-time game engines, speech recognizers) thus involve many tunable configuration parameters. These parameters are often specified and hard-coded into the software by various developers or teams. If optimized jointly, these parameters can result in significant improvements. Bayesian optimization is a powerful tool for the joint optimization of design choices that is gaining great popularity in recent years. It promises greater automation so as to increase both product quality and human productivity. This review paper introduces Bayesian optimization, highlights some of its methodological aspects, and showcases a wide range of applications.},
	pages = {148--175},
	number = {1},
	journaltitle = {Proceedings of the {IEEE}},
	author = {Shahriari, B. and Swersky, K. and Wang, Z. and Adams, R. P. and Freitas, N. de},
	date = {2016-01},
	keywords = {Bayesian optimization, Bayes methods, Big Data, Big data application, Decision making, Design of experiments, Genomes, genomic medicine, human productivity, large-scale heterogeneous computing, Linear programming, massive complex software system, optimisation, Optimization, product quality, response surface methodology, Statistical analysis, statistical learning, storage allocation, storage architecture},
	file = {IEEE Xplore Abstract Record:/home/student/m/mmeier/.mozilla/firefox/zg92muzl.default-1472461511945/zotero/storage/E468D38T/abs_all.html:text/html}
}

@article{mockus_application_1978,
	title = {The application of Bayesian methods for seeking the extremum},
	volume = {2},
	pages = {2},
	number = {117},
	journaltitle = {Towards global optimization},
	author = {Mockus, Jonas and Tiesis, Vytautas and Zilinskas, Antanas},
	date = {1978}
}

@article{bartz-beielstein_spot:_2010,
	title = {{SPOT}: An R package for automatic and interactive tuning of optimization algorithms by sequential parameter optimization},
	url = {http://arxiv.org/abs/1006.4645},
	shorttitle = {{SPOT}},
	journaltitle = {{arXiv} preprint {arXiv}:1006.4645},
	author = {Bartz-Beielstein, Thomas},
	urldate = {2016-07-06},
	date = {2010}
}

@inproceedings{eggensperger_efficient_2015,
	title = {Efficient Benchmarking of Hyperparameter Optimizers via Surrogates.},
	url = {http://aad.informatik.uni-freiburg.de/papers/15-AAAI-Surrogates.pdf},
	pages = {1114--1120},
	booktitle = {{AAAI}},
	author = {Eggensperger, Katharina and Hutter, Frank and Hoos, Holger H. and Leyton-Brown, Kevin},
	urldate = {2016-06-30},
	date = {2015}
}

@thesis{brochu_interactive_2010,
	title = {Interactive Bayesian Optimization},
	institution = {The University of British Columbia (Vancouver},
	type = {phdthesis},
	author = {Brochu, Eric},
	date = {2010}
}

@article{jones_taxonomy_2001,
	title = {A taxonomy of global optimization methods based on response surfaces},
	volume = {21},
	url = {http://link.springer.com/article/10.1023/A:1012771025575},
	pages = {345--383},
	number = {4},
	journaltitle = {Journal of global optimization},
	author = {Jones, Donald R.},
	urldate = {2016-05-16},
	date = {2001},
	file = {Snapshot:/home/student/m/mmeier/.mozilla/firefox/zg92muzl.default-1472461511945/zotero/storage/IE8EG78I/A1012771025575.html:text/html}
}

@article{claesen_hyperparameter_2015,
	title = {Hyperparameter Search in Machine Learning},
	url = {http://arxiv.org/abs/1502.02127},
	journaltitle = {{arXiv} preprint {arXiv}:1502.02127},
	author = {Claesen, Marc and De Moor, Bart},
	urldate = {2016-07-01},
	date = {2015}
}

@inproceedings{ghoting_systemml:_2011,
	title = {{SystemML}: Declarative machine learning on {MapReduce}},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5767930},
	shorttitle = {{SystemML}},
	pages = {231--242},
	booktitle = {Data Engineering ({ICDE}), 2011 {IEEE} 27th International Conference on},
	publisher = {{IEEE}},
	author = {Ghoting, Amol and Krishnamurthy, Rajasekar and Pednault, Edwin and Reinwald, Berthold and Sindhwani, Vikas and Tatikonda, Shirish and Tian, Yuanyuan and Vaithyanathan, Shivakumar},
	urldate = {2016-06-09},
	date = {2011},
	file = {Snapshot:/home/student/m/mmeier/.mozilla/firefox/zg92muzl.default-1472461511945/zotero/storage/CG2Q2T3T/login.html:text/html}
}

@incollection{snoek_practical_2012,
	title = {Practical Bayesian Optimization of Machine Learning Algorithms},
	url = {http://papers.nips.cc/paper/4522-practical-bayesian-optimization-of-machine-learning-algorithms.pdf},
	pages = {2951--2959},
	booktitle = {Advances in Neural Information Processing Systems 25},
	publisher = {Curran Associates, Inc.},
	author = {Snoek, Jasper and Larochelle, Hugo and Adams, Ryan P},
	editor = {Pereira, F. and Burges, C. J. C. and Bottou, L. and Weinberger, K. Q.},
	urldate = {2016-05-16},
	date = {2012},
	file = {NIPS Snapshort:/home/student/m/mmeier/.mozilla/firefox/zg92muzl.default-1472461511945/zotero/storage/V3EB4AZ8/4522-practical.html:text/html}
}

@inproceedings{hutter_evaluation_2013,
	title = {An evaluation of sequential model-based optimization for expensive blackbox functions},
	url = {http://dl.acm.org/citation.cfm?id=2501592},
	pages = {1209--1216},
	booktitle = {Proceedings of the 15th annual conference companion on Genetic and evolutionary computation},
	publisher = {{ACM}},
	author = {Hutter, Frank and Hoos, Holger and Leyton-Brown, Kevin},
	urldate = {2016-07-07},
	date = {2013}
}

@article{huang_global_2006,
	title = {Global Optimization of Stochastic Black-Box Systems via Sequential Kriging Meta-Models},
	volume = {34},
	issn = {0925-5001, 1573-2916},
	url = {http://link.springer.com/10.1007/s10898-005-2454-3},
	doi = {10.1007/s10898-005-2454-3},
	pages = {441--466},
	number = {3},
	journaltitle = {Journal of Global Optimization},
	author = {Huang, D. and Allen, T. T. and Notz, W. I. and Zeng, N.},
	urldate = {2016-07-07},
	date = {2006-03},
	langid = {english}
}

@incollection{krause_contextual_2011,
	title = {Contextual Gaussian Process Bandit Optimization},
	url = {http://papers.nips.cc/paper/4487-contextual-gaussian-process-bandit-optimization.pdf},
	pages = {2447--2455},
	booktitle = {Advances in Neural Information Processing Systems 24},
	publisher = {Curran Associates, Inc.},
	author = {Krause, Andreas and Ong, Cheng S.},
	editor = {Shawe-Taylor, J. and Zemel, R. S. and Bartlett, P. L. and Pereira, F. and Weinberger, K. Q.},
	urldate = {2016-05-16},
	date = {2011},
	file = {NIPS Snapshort:/home/student/m/mmeier/.mozilla/firefox/zg92muzl.default-1472461511945/zotero/storage/GP2MZKGZ/4487-contextual-gaussian-process-bandit-optimization.html:text/html}
}

@incollection{hu_survey_2012,
	title = {A survey of some model-based methods for global optimization},
	url = {http://link.springer.com/chapter/10.1007/978-0-8176-8337-5_10},
	pages = {157--179},
	booktitle = {Optimization, Control, and Applications of Stochastic Systems},
	publisher = {Springer},
	author = {Hu, Jiaqiao and Wang, Yongqiang and Zhou, Enlu and Fu, Michael C. and Marcus, Steven I.},
	urldate = {2016-05-16},
	date = {2012}
}

@inproceedings{hutter_efficient_2014,
	title = {An efficient approach for assessing hyperparameter importance},
	url = {http://machinelearning.wustl.edu/mlpapers/papers/icml2014c1_hutter14},
	pages = {754--762},
	booktitle = {Proceedings of the 31st International Conference on Machine Learning ({ICML}-14)},
	author = {Hutter, Frank and Hoos, Holger and Leyton-Brown, Kevin},
	urldate = {2016-01-31},
	date = {2014}
}

@thesis{pelikan_bayesian_2002,
	title = {Bayesian optimization algorithm: From single level to hierarchy},
	url = {http://martinpelikan.net/files/2002023.pdf},
	shorttitle = {Bayesian optimization algorithm},
	institution = {{PhD} thesis, University of Illinois at Urbana-Champaign, Urbana, {IL}, 2002. Also {IlliGAL} Report},
	type = {phdthesis},
	author = {Pelikan, Martin and Goldberg, David E.},
	urldate = {2016-07-08},
	date = {2002}
}

@thesis{gelbart_constrained_2015,
	title = {Constrained Bayesian Optimization and Applications},
	url = {https://dash.harvard.edu/handle/1/17467236},
	type = {phdthesis},
	author = {Gelbart, Michael Adam},
	urldate = {2016-07-08},
	date = {2015}
}

@article{wang_bayesian_2016,
	title = {Bayesian optimization in a billion dimensions via random embeddings},
	volume = {55},
	url = {http://www.jair.org/papers/paper4806.html},
	pages = {361--387},
	journaltitle = {Journal of Artificial Intelligence Research},
	author = {Wang, Ziyu and Hutter, Frank and Zoghi, Masrour and Matheson, David and de Feitas, Nando},
	urldate = {2016-06-23},
	date = {2016}
}

@online{_evaluating_2016,
	title = {Evaluating Hyperparameter Optimization Strategies},
	url = {http://blog.sigopt.com/post/144221180573/evaluating-hyperparameter-optimization-strategies},
	abstract = {By: Alexandra Johnson, Software Engineer
Hyperparameter optimization is a common problem in machine learning. Machine learning algorithms, from logistic regression to neural nets, depend on well tuned...},
	titleaddon = {{SigOpt} Blog},
	urldate = {2016-06-23},
	date = {2016-05-11},
	file = {Snapshot:/home/student/m/mmeier/.mozilla/firefox/zg92muzl.default-1472461511945/zotero/storage/NR8QE7EZ/evaluating-hyperparameter-optimization-strategies.html:text/html}
}

@article{_hyperparameter_2015,
	title = {Hyperparameter Optimization with Factorized Multilayer Perceptrons},
	url = {https://www.ismll.uni-hildesheim.de/pub/pdfs/schilling2015-ecml.pdf},
	urldate = {2016-06-30},
	date = {2015}
}

@thesis{grosse_model_2014,
	title = {Model selection in compositional spaces},
	url = {http://dspace.mit.edu/handle/1721.1/87789},
	institution = {Massachusetts Institute of Technology},
	type = {phdthesis},
	author = {Grosse, Roger Baker},
	urldate = {2016-02-23},
	date = {2014},
	file = {Snapshot:/home/student/m/mmeier/.mozilla/firefox/zg92muzl.default-1472461511945/zotero/storage/PHIGH939/87789.html:text/html}
}

@article{thakur_autocompete:_2015,
	title = {{AutoCompete}: A Framework for Machine Learning Competition},
	url = {http://arxiv.org/abs/1507.02188},
	shorttitle = {{AutoCompete}},
	abstract = {In this paper, we propose {AutoCompete}, a highly automated machine learning framework for tackling machine learning competitions. This framework has been learned by us, validated and improved over a period of more than two years by participating in online machine learning competitions. It aims at minimizing human interference required to build a first useful predictive model and to assess the practical difficulty of a given machine learning challenge. The proposed system helps in identifying data types, choosing a machine learn- ing model, tuning hyper-parameters, avoiding over-fitting and optimization for a provided evaluation metric. We also observe that the proposed system produces better (or comparable) results with less runtime as compared to other approaches.},
	journaltitle = {{arXiv}:1507.02188 [cs, stat]},
	author = {Thakur, Abhishek and Krohn-Grimberghe, Artus},
	urldate = {2016-04-16},
	date = {2015-07-08},
	eprinttype = {arxiv},
	eprint = {1507.02188},
	keywords = {Computer Science - Learning, Statistics - Machine Learning},
	file = {arXiv.org Snapshot:/home/student/m/mmeier/.mozilla/firefox/zg92muzl.default-1472461511945/zotero/storage/ZN3E7HXR/1507.html:text/html}
}

@inproceedings{bergstra_making_2013,
	title = {Making a science of model search: Hyperparameter optimization in hundreds of dimensions for vision architectures},
	url = {http://jmlr.org/proceedings/papers/v28/bergstra13.html},
	shorttitle = {Making a science of model search},
	pages = {115--123},
	booktitle = {Proceedings of The 30th International Conference on Machine Learning},
	author = {Bergstra, James and Yamins, Daniel and Cox, David},
	urldate = {2016-01-18},
	date = {2013}
}

@article{smith_easy_2014,
	title = {An easy to use repository for comparing and improving machine learning algorithm usage},
	url = {http://arxiv.org/abs/1405.7292},
	journaltitle = {{arXiv} preprint {arXiv}:1405.7292},
	author = {Smith, Michael R. and White, Andrew and Giraud-Carrier, Christophe and Martinez, Tony},
	urldate = {2016-05-17},
	date = {2014}
}

@article{samuel_y._dennis_iii_bayesian_1996,
	title = {A Bayesian  analysis of tree-structured statistical decision problems},
	url = {http://ac.els-cdn.com/0378375895001123/1-s2.0-0378375895001123-main.pdf?_tid=d059d40c-316d-11e6-b5e5-00000aab0f6b&acdnat=1465826019_a08260ada3ee576e062bae5275f425b9},
	author = {{Samuel Y. Dennis III}},
	urldate = {2016-06-13},
	date = {1996}
}

@article{hutter_paramils:_2009,
	title = {{ParamILS}: an automatic algorithm configuration framework},
	volume = {36},
	url = {http://www.aaai.org/Papers/JAIR/Vol36/JAIR-3606.pdf},
	shorttitle = {{ParamILS}},
	pages = {267--306},
	number = {1},
	journaltitle = {Journal of Artificial Intelligence Research},
	author = {Hutter, Frank and Hoos, Holger H. and Leyton-Brown, Kevin and Stützle, Thomas},
	urldate = {2016-07-23},
	date = {2009}
}

@inproceedings{hutter_performance_2006,
	title = {Performance prediction and automated tuning of randomized and parametric algorithms},
	url = {http://link.springer.com/chapter/10.1007/11889205_17},
	pages = {213--228},
	booktitle = {International Conference on Principles and Practice of Constraint Programming},
	publisher = {Springer},
	author = {Hutter, Frank and Hamadi, Youssef and Hoos, Holger H. and Leyton-Brown, Kevin},
	urldate = {2016-07-07},
	date = {2006}
}

@inproceedings{regolin_bayesian_2005,
	title = {Bayesian automatic programming},
	url = {http://link.springer.com/chapter/10.1007/978-3-540-31989-4_4},
	pages = {38--49},
	booktitle = {European Conference on Genetic Programming},
	publisher = {Springer},
	author = {Regolin, Evandro Nunes and Pozo, Aurora Trindad Ramirez},
	urldate = {2016-07-13},
	date = {2005}
}

@online{_taxonomy_????,
	title = {A taxonomy of Hybrid Metaheuristics},
	url = {https://www.researchgate.net/profile/El_Ghazali_Talbi/publication/225364702_A_Taxonomy_of_Hybrid_Metaheuristics/links/56ba136d08ae3a9ac436586e.pdf},
	urldate = {2016-07-01}
}

@article{guyon_automl_2015,
	title = {{AutoML} Challenge 2015: Design and First Results},
	url = {http://sergioescalera.com/wp-content/uploads/2015/07/automl15.pdf},
	shorttitle = {{AutoML} Challenge 2015},
	author = {Guyon, Isabelle and Bennett, Kristin and Cawley, Gavin and Escalante, Hugo Jair and Escalera, Sergio and Ho, Tin Kam and Ray, Bisakha and Saeed, Mehreen and Statnikov, Alexander and Viegas, Evelyne},
	urldate = {2016-04-23},
	date = {2015}
}

@article{hutter_beyond_2015,
	title = {Beyond Manual Tuning of Hyperparameters},
	volume = {29},
	issn = {0933-1875, 1610-1987},
	url = {http://link.springer.com/article/10.1007/s13218-015-0381-0},
	doi = {10.1007/s13218-015-0381-0},
	abstract = {The success of hand-crafted machine learning systems in many applications raises the question of making machine learning algorithms more autonomous, i.e., to reduce the requirement of expert input to a minimum. We discuss two strategies towards this goal: (1) automated optimization of hyperparameters (including mechanisms for feature selection, preprocessing, model selection, etc) and (2) the development of algorithms with reduced sets of hyperparameters. Since many research directions (e.g., deep learning), show a tendency towards increasingly complex algorithms with more and more hyperparamters, the demand for both of these strategies continuously increases. We review recent hyperparameter optimization methods and discuss data-driven approaches to avoid the introduction of hyperparameters using unsupervised learning. We end in discussing how these complementary strategies can work hand-in-hand, representing a very promising approach towards autonomous machine learning.},
	pages = {329--337},
	number = {4},
	journaltitle = {Künstl Intell},
	author = {Hutter, Frank and Lücke, Jörg and Schmidt-Thieme, Lars},
	urldate = {2016-04-25},
	date = {2015-07-11},
	langid = {english},
	keywords = {Artificial Intelligence (incl. Robotics), Automatic machine learning, Autonomous learning, Deep learning, Hyperparameter optimization, Software Engineering/Programming and Operating Systems}
}

@article{jones_efficient_1998,
	title = {Efficient global optimization of expensive black-box functions},
	volume = {13},
	url = {http://link.springer.com/article/10.1023/A:1008306431147},
	pages = {455--492},
	number = {4},
	journaltitle = {Journal of Global optimization},
	author = {Jones, Donald R. and Schonlau, Matthias and Welch, William J.},
	urldate = {2016-05-16},
	date = {1998}
}

@online{_how_2015,
	title = {How to Evaluate Machine Learning Models: Hyperparameter Tuning},
	url = {http://blog.dato.com/how-to-evaluate-machine-learning-models-part-4-hyperparameter-tuning},
	urldate = {2016-06-30},
	date = {2015-05-27},
	file = {How to Evaluate Machine Learning Models\: Hyperparameter Tuning:/home/student/m/mmeier/.mozilla/firefox/zg92muzl.default-1472461511945/zotero/storage/HQ8PKS98/how-to-evaluate-machine-learning-models-part-4-hyperparameter-tuning.html:text/html}
}

@inproceedings{snoek_scalable_2015,
	title = {Scalable bayesian optimization using deep neural networks},
	url = {http://www.jmlr.org/proceedings/papers/v37/snoek15.pdf},
	booktitle = {International Conference on Machine Learning},
	author = {Snoek, Jasper and Rippel, Oren and Swersky, Kevin and Kiros, Ryan and Satish, Nadathur and Sundaram, Narayanan and Patwary, Mostofa and Ali, Mostofa and Adams, Ryan P. and {others}},
	urldate = {2016-08-21},
	date = {2015}
}

@article{swersky_freeze-thaw_2014,
	title = {Freeze-thaw Bayesian optimization},
	url = {http://arxiv.org/abs/1406.3896},
	journaltitle = {{arXiv} preprint {arXiv}:1406.3896},
	author = {Swersky, Kevin and Snoek, Jasper and Adams, Ryan Prescott},
	urldate = {2016-04-28},
	date = {2014}
}

@article{bergstra_random_2012,
	title = {Random search for hyper-parameter optimization},
	volume = {13},
	url = {http://dl.acm.org/citation.cfm?id=2188395},
	pages = {281--305},
	number = {1},
	journaltitle = {The Journal of Machine Learning Research},
	author = {Bergstra, James and Bengio, Yoshua},
	urldate = {2016-05-11},
	date = {2012}
}

@article{guyon_design_2015,
	title = {Design of the 2015 {ChaLearn} {AutoML} Challenge},
	url = {http://www.causality.inf.ethz.ch/AutoML/automl_ijcnn15.pdf},
	author = {Guyon, Isabelle and Bennett, Kristin and Cawley, Gavin and Escalante, Hugo Jair and Escalera, Sergio and Ho, Tin Kam and Macia, Núria and Ray, Bisakha and Saeed, Mehreen and Statnikov, Alexander and {others}},
	urldate = {2016-01-18},
	date = {2015}
}

@article{_metalearning_2012,
	title = {Metalearning for Data Mining and {KDD}},
	url = {http://www.fit.vutbr.cz/study/courses/VPD/public/1213VPD-Striz.pdf},
	urldate = {2016-08-08},
	date = {2012}
}

@article{lemke_metalearning:_2013,
	title = {Metalearning: a survey of trends and technologies},
	volume = {44},
	issn = {0269-2821, 1573-7462},
	url = {http://link.springer.com/article/10.1007/s10462-013-9406-y},
	doi = {10.1007/s10462-013-9406-y},
	shorttitle = {Metalearning},
	abstract = {Metalearning attracted considerable interest in the machine learning community in the last years. Yet, some disagreement remains on what does or what does not constitute a metalearning problem and in which contexts the term is used in. This survey aims at giving an all-encompassing overview of the research directions pursued under the umbrella of metalearning, reconciling different definitions given in scientific literature, listing the choices involved when designing a metalearning system and identifying some of the future research challenges in this domain.},
	pages = {117--130},
	number = {1},
	journaltitle = {Artif Intell Rev},
	author = {Lemke, Christiane and Budka, Marcin and Gabrys, Bogdan},
	urldate = {2016-05-16},
	date = {2013-07-20},
	langid = {english},
	file = {Snapshot:/home/student/m/mmeier/.mozilla/firefox/zg92muzl.default-1472461511945/zotero/storage/MPR34G88/s10462-013-9406-y.html:text/html}
}

@inproceedings{maclaurin_gradient-based_2015,
	title = {Gradient-based hyperparameter optimization through reversible learning},
	url = {http://www.jmlr.org/proceedings/papers/v37/maclaurin15.pdf},
	booktitle = {Proceedings of the 32nd International Conference on Machine Learning},
	author = {Maclaurin, Dougal and Duvenaud, David and Adams, Ryan P.},
	urldate = {2016-06-30},
	date = {2015}
}

@article{pedregosa_hyperparameter_2016,
	title = {Hyperparameter optimization with approximate gradient},
	url = {http://arxiv.org/abs/1602.02355},
	journaltitle = {{arXiv} preprint {arXiv}:1602.02355},
	author = {Pedregosa, Fabian},
	urldate = {2016-07-01},
	date = {2016}
}

@article{moradabadi_new_2016,
	title = {A new real-coded stochastic Bayesian optimization algorithm for continuous global optimization},
	volume = {17},
	issn = {1389-2576, 1573-7632},
	url = {http://link.springer.com/10.1007/s10710-015-9255-3},
	doi = {10.1007/s10710-015-9255-3},
	pages = {145--167},
	number = {2},
	journaltitle = {Genetic Programming and Evolvable Machines},
	author = {Moradabadi, Behnaz and Ebadzadeh, Mohammad Mahdi and Meybodi, Mohammad Reza},
	urldate = {2016-09-09},
	date = {2016-06},
	langid = {english},
	file = {art%3A10.1007%2Fs10710-015-9255-3.pdf:/home/student/m/mmeier/.mozilla/firefox/zg92muzl.default-1472461511945/zotero/storage/XFXDD89P/art%3A10.1007%2Fs10710-015-9255-3.pdf:application/pdf}
}

@article{dewancker_bayesain_2016,
	title = {Bayesain Optimization Primer},
	author = {Dewancker, Ian and {McCourt}, Michael and Clark, Scott},
	date = {2016},
	keywords = {Pattern recognition systems, Statistical decision},
	file = {SigOpt_Bayesian_Optimization_Primer.pdf:/home/student/m/mmeier/.mozilla/firefox/zg92muzl.default-1472461511945/zotero/storage/DQXF85FZ/SigOpt_Bayesian_Optimization_Primer.pdf:application/pdf}
}

@article{dewancker_stratified_2016,
	title = {A Stratified Analysis of Bayesian Optimization Methods},
	url = {http://arxiv.org/abs/1603.09441},
	journaltitle = {{arXiv} preprint {arXiv}:1603.09441},
	author = {Dewancker, Ian and {McCourt}, Michael and Clark, Scott and Hayes, Patrick and Johnson, Alexandra and Ke, George},
	urldate = {2016-09-09},
	date = {2016},
	file = {1603.09441v1.pdf:/home/student/m/mmeier/.mozilla/firefox/zg92muzl.default-1472461511945/zotero/storage/KWNZH2RS/1603.09441v1.pdf:application/pdf}
}

@article{dewancker_evaluation_2016,
	title = {Evaluation System for a Bayesian Optimization Service},
	url = {http://arxiv.org/abs/1605.06170},
	journaltitle = {{arXiv} preprint {arXiv}:1605.06170},
	author = {Dewancker, Ian and {McCourt}, Michael and Clark, Scott and Hayes, Patrick and Johnson, Alexandra and Ke, George},
	urldate = {2016-09-09},
	date = {2016},
	file = {1605.06170v1.pdf:/home/student/m/mmeier/.mozilla/firefox/zg92muzl.default-1472461511945/zotero/storage/VGBK4XDC/1605.06170v1.pdf:application/pdf}
}

@inproceedings{bergstra_implementations_2011,
	title = {Implementations of algorithms for hyper-parameter optimization},
	url = {http://www.cs.ubc.ca/~hutter/nips2011workshop/papers_and_posters/Bergstra-abstract.pdf},
	pages = {29},
	booktitle = {{NIPS} Workshop on Bayesian optimization},
	author = {Bergstra, James and Bardenet, Rémi and Kégl, B. and Bengio, Y.},
	urldate = {2016-09-09},
	date = {2011},
	file = {Bergstra-abstract.pdf:/home/student/m/mmeier/.mozilla/firefox/zg92muzl.default-1472461511945/zotero/storage/M6JJ7V4Z/Bergstra-abstract.pdf:application/pdf}
}

@inproceedings{bergstra_machine_2012,
	title = {Machine learning for predictive auto-tuning with boosted regression trees},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6339587},
	pages = {1--9},
	booktitle = {Innovative Parallel Computing ({InPar}), 2012},
	publisher = {{IEEE}},
	author = {Bergstra, James and Pinto, Nicolas and Cox, David},
	urldate = {2016-09-09},
	date = {2012},
	file = {12_inpar.pdf:/home/student/m/mmeier/.mozilla/firefox/zg92muzl.default-1472461511945/zotero/storage/3XVPABMW/12_inpar.pdf:application/pdf}
}

@article{lacoste_sequential_2014,
	title = {Sequential model-based ensemble optimization},
	url = {http://arxiv.org/abs/1402.0796},
	journaltitle = {{arXiv} preprint {arXiv}:1402.0796},
	author = {Lacoste, Alexandre and Larochelle, Hugo and Laviolette, François and Marchand, Mario},
	urldate = {2016-09-14},
	date = {2014}
}

@inproceedings{feurer_efficient_2015,
	title = {Efficient and robust automated machine learning},
	url = {http://papers.nips.cc/paper/5872-efficient-and-robust-automated-machine-learning},
	pages = {2962--2970},
	booktitle = {Advances in Neural Information Processing Systems},
	author = {Feurer, Matthias and Klein, Aaron and Eggensperger, Katharina and Springenberg, Jost and Blum, Manuel and Hutter, Frank},
	urldate = {2016-09-14},
	date = {2015}
}

@article{f._mascia_grammar-based_????,
	title = {Grammar-based Generation of Stochastic Local Search Heuristics Through Automatic Algorithm Configuration Tools},
	issn = {1781-3794},
	url = {http://iridia.ulb.ac.be/IridiaTrSeries/link/IridiaTr2013-015.pdf},
	abstract = {Several grammar-based genetic programming algorithms have been proposed in the literature
to automatically generate heuristics for hard optimisation problems. These approaches specify the
algorithmic building blocks and the way in which they can be combined in a grammar; the best
heuristic for the problem being tackled is found by an evolutionary algorithm that searches in the
algorithm design space defined by the grammar.
In this work, we propose a novel representation of the grammar into a sequence of categorical,
integer, and real-valued parameters. We then use a tool for automatic algorithm configuration to
search for the best algorithm for the problem at hand. Our experimental evaluation on the onedimensional
bin packing problem and the permutation flowshop problem with weighted tardiness
objective shows that the proposed approach improves over grammatical evolution, a well-established
variant of grammar-based genetic programming. The reasons behind such improvement lie both in
the representation proposed, as well as in the method used to search the algorithm design space.},
	author = {{F. Mascia} and {T. Stützle} and {M. Lopez-Ibanez} and {J. Dubois-Lacoste}},
	urldate = {2016-10-01}
}

@article{levesque_bayesian_2016,
	title = {Bayesian Hyperparameter Optimization for Ensemble Learning},
	url = {http://arxiv.org/abs/1605.06394},
	journaltitle = {{arXiv} preprint {arXiv}:1605.06394},
	author = {Lévesque, Julien-Charles and Gagné, Christian and Sabourin, Robert},
	urldate = {2016-10-05},
	date = {2016},
	file = {73.pdf:/home/student/m/mmeier/.mozilla/firefox/zg92muzl.default-1472461511945/zotero/storage/IQ3KMHE4/73.pdf:application/pdf}
}

@article{laanaya_learning_2011,
	title = {Learning general Gaussian kernel hyperparameters of {SVMs} using optimization on symmetric positive-definite matrices manifold},
	volume = {32},
	issn = {01678655},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S016786551100153X},
	doi = {10.1016/j.patrec.2011.05.009},
	pages = {1511--1515},
	number = {13},
	journaltitle = {Pattern Recognition Letters},
	author = {Laanaya, Hicham and Abdallah, Fahed and Snoussi, Hichem and Richard, Cédric},
	urldate = {2016-10-05},
	date = {2011-10},
	langid = {english},
	file = {laanaya2011learning.pdf:/home/student/m/mmeier/.mozilla/firefox/zg92muzl.default-1472461511945/zotero/storage/9UDERZBC/laanaya2011learning.pdf:application/pdf}
}

@article{jamieson_non-stochastic_2015,
	title = {Non-stochastic best arm identification and hyperparameter optimization},
	url = {http://www.jmlr.org/proceedings/papers/v51/jamieson16.pdf},
	journaltitle = {Preprint available a t},
	author = {Jamieson, Kevin and Talwalkar, Ameet},
	urldate = {2016-10-05},
	date = {2015},
	file = {1502.07943.pdf:/home/student/m/mmeier/.mozilla/firefox/zg92muzl.default-1472461511945/zotero/storage/QST3Z5SF/1502.07943.pdf:application/pdf}
}

@article{pandita_extending_2016,
	title = {Extending Expected Improvement for High-dimensional Stochastic Optimization of Expensive Black-Box Functions},
	url = {http://arxiv.org/abs/1604.01147},
	journaltitle = {{arXiv} preprint {arXiv}:1604.01147},
	author = {Pandita, Piyush and Bilionis, Ilias and Panchal, Jitesh},
	urldate = {2016-10-08},
	date = {2016}
}

@article{srinivas_gaussian_2009,
	title = {Gaussian process optimization in the bandit setting: No regret and experimental design},
	url = {http://arxiv.org/abs/0912.3995},
	shorttitle = {Gaussian process optimization in the bandit setting},
	journaltitle = {{arXiv} preprint {arXiv}:0912.3995},
	author = {Srinivas, Niranjan and Krause, Andreas and Kakade, Sham M. and Seeger, Matthias},
	urldate = {2016-10-09},
	date = {2009}
}

@article{betro_bayesian_1990,
	title = {Bayesian Methods in Global Optimization},
	url = {http://download.springer.com/static/pdf/572/art%253A10.1007%252FBF00120661.pdf?originUrl=http%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2FBF00120661&token2=exp=1476355826~acl=%2Fstatic%2Fpdf%2F572%2Fart%25253A10.1007%25252FBF00120661.pdf%3ForiginUrl%3Dhttp%253A%252F%252Flink.springer.com%252Farticle%252F10.1007%252FBF00120661*~hmac=e5cd63c1af65676d18d78f2d274455c16d374a0ae3cd7888c76b4fac344f46f6},
	author = {Betro, Bruno},
	urldate = {2016-10-13},
	date = {1990},
	keywords = {Bayesian inference, decision theory, multistart method, stochastic processes, stopping rule},
	file = {art%3A10.1007%2FBF00120661.pdf:/home/student/m/mmeier/.mozilla/firefox/zg92muzl.default-1472461511945/zotero/storage/TDJZBEG9/art%3A10.1007%2FBF00120661.pdf:application/pdf}
}

@inproceedings{carr_basc:_2016,
	title = {{BASC}: Applying Bayesian Optimization to the Search for Global Minima on Potential Energy Surfaces},
	url = {http://www.jmlr.org/proceedings/papers/v48/carr16.pdf},
	shorttitle = {{BASC}},
	pages = {898--907},
	booktitle = {Proceedings of The 33rd International Conference on Machine Learning},
	author = {Carr, Shane and Garnett, Roman and Lo, Cynthia},
	urldate = {2016-10-13},
	date = {2016},
	file = {carr16.pdf:/home/student/m/mmeier/.mozilla/firefox/zg92muzl.default-1472461511945/zotero/storage/T8JDVKKT/carr16.pdf:application/pdf}
}

@article{mockus_bayesian_1974,
	title = {{ON} {BAYESIAN}  {METHODS}  {FOR}  {SEEKING}  {THE} {EXTREMUM}},
	url = {http://download.springer.com/static/pdf/22/chp%253A10.1007%252F3-540-07165-2_55.pdf?originUrl=http%3A%2F%2Flink.springer.com%2Fchapter%2F10.1007%2F3-540-07165-2_55&token2=exp=1476359445~acl=%2Fstatic%2Fpdf%2F22%2Fchp%25253A10.1007%25252F3-540-07165-2_55.pdf%3ForiginUrl%3Dhttp%253A%252F%252Flink.springer.com%252Fchapter%252F10.1007%252F3-540-07165-2_55*~hmac=9113c2e0a8c9534935a0607c58b2f4a718f2d51702d9162263226a7968bb6773},
	author = {Mockus, Jonas},
	urldate = {2016-10-13},
	date = {1974},
	file = {chp%3A10.1007%2F3-540-07165-2_55.pdf:/home/student/m/mmeier/.mozilla/firefox/zg92muzl.default-1472461511945/zotero/storage/DEDP2QK9/chp%3A10.1007%2F3-540-07165-2_55.pdf:application/pdf}
}

@unpublished{brise_lipschitzian_2008,
	title = {Lipschitzian Optimization, {DIRECT} Algorithm, and Applications},
	url = {https://www.inf.ethz.ch/personal/ybrise/data/talks/msem20080401.pdf},
	author = {Brise, Yves},
	urldate = {2016-10-13},
	date = {2008-04-01},
	file = {msem20080401.pdf:/home/student/m/mmeier/.mozilla/firefox/zg92muzl.default-1472461511945/zotero/storage/SN64HC57/msem20080401.pdf:application/pdf}
}