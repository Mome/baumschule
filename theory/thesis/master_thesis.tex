\documentclass[english]{article}
\usepackage{dot2texi}
\usepackage[utf8]{inputenc}
%\usepackage{babel}
\usepackage[backend=bibtex]{biblatex}
\usepackage{hyperref}
\usepackage{mathtools}
\usepackage[printonlyused]{acronym}
\usepackage{minted}
\usepackage{amsthm}
\usepackage{tikz}

\usetikzlibrary{shapes,arrows}

\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

\bibliography{library.bib}

% Add mathematical foo
\newcommand{\EI}{\operatorname{EI}}
\newcommand{\normal}{\mathcal{N}}

\begin{document}

\title{Bayesian Hyperparameter-Optimization in Grammer-Based Search Spaces}
\author{Moritz Meier}
\maketitle
\tableofcontents
\newpage

\section*{List of Acronyms}
  \begin{acronym}
  \acro{AI}{artificial intelligence}
  \acro{BO}{Bayesian Optimization}
  \acro{BOA}{Bayesian optimization algorithm}
  \acro{BGO}{Bayesian global optimization}
  \acro{DAG}{directed acyclic graph}
  \acro{EGO}{efficient global optimization}
  \acro{GO}{global optimization}
  \acro{HPO}{hyperparameter optimization}
  \acro{IAF}{information acquisition function}
  \acro{ML}{machine learning}
  \acro{SMAC}{sequential model-based algorithm configuration}
  \acro{SMBO}{sequential model-based optimization}
\end{acronym}

\section{Introduction}

The mathematical branch of Optimization is mathematical programming, where a mathematical program referes to an optimization problem with additional equality and inequality constraints.

Metaheuristics
Programm Configuration
Learning \& Optimizaion.


\section{Global Black-Box Optimization}

\subsection{Distinctions}

\subsubsection*{gradient based vs. derivative free}
also

\subsubsection*{Local vs. Global}

\subsubsection*{Heuristic strategies vs. Exect methods}
aka. stochastic vs deterministic

\subsubsection*{model-based vs. instance-based}
More sophisticated \ac{GO} algorithms can be devided into
a.k.a. - model-free or direct

\subsubsection*{multi vs. single instance}

\subsubsection*{exploration-exploitation tradeoff}

\subsubsection*{interactive}

\subsubsection*{predictive vs. explanatory model}

\subsubsection*{parallelizabel}

\subsubsection*{stochastic objective function}

\subsubsection*{single vs multiobjective}

\subsubsection*{approximations}
 - early stopping
 - data subset

 \subsection{computational costs}
 - space \& time
 - intelligent selection vs massive sampling tradeoff


The use of stochastic processe in \ac{GO} for surrogate fitting is called \ac{BO}. This approach was first explored by Harold Kushner in 1964 \cite{kushner_new_1964}. In \cite{jones_efficient_1998} the surrogate is also called \textit{figure of merrit}.


\subsection{Active Learning}


\subsection{Bandit Problem}


\section{Hyperparameter Optimization}
In Bayesain statistics the term \textit{hyperparameter} referes to the a parameter of the prior distribution. In \textit{hierarchical models} the priors distribution over the hyperparamters are called \textit{hyperpriors} respectively \cite[p.408]{bishop_neural_1995}. In \acf{machine learning} a hyperparameter is any parameter that needs to be assigned before the training of other parameters can begin.
\acf{HPO} Other terms for \ac{HPO} are hyperarameter \textit{tuning} or \textit{search}. Also \textit{model selection} means essentially the same thing, the focus is however more on the selection criterions.
The ususal \ac{HPO} procedure ...
Key characteristics of a \ac{HPO} problems are:
\paragraph{Long evaluation times}
\paragraph{Little knowledge} of the objective function
\paragraph{varying complexity} of search space ranging from simple homogenic cartesian search spaces to heterogenic graph shaped spaces.

\subsection{Machine Learning as Optimization}



Most \acf{ML} problems are expressable as optimization problems \cite{bennett_interplay_2006}.

\paragraph{Types and Error Functions}


\paragraph{Model Selection}



\begin{quote}
Machine learning algorithms, however, have certain characteristics that distinguish them from other black-box optimization problems.  First, each function evaluation can require a variable amount of time:  training a small neural network with 10 hidden units will take less time than a bigger net-work with 1000 hidden units.  Even without considering duration, the advent of cloud computing makes it possible to quantify economically the cost of requiring large-memory machines for learning, changing the actual cost in dollars of an experiment with a different number of hidden units.
\end{quote}
Second, machine learning experiment EGO algorithm
 - Categrorical
 - Discrete
 - Continunous


\subsection{Combinators}
Join and prod over parameter-lists form an idempotent semiring:

$(A, \cup)$ is a idempotent commutative monoid (or join-semilatice with zero) with identity element $\emptyset$:
$$(a \cup b) \cup c = a \cup (b \cup c)$$
$$\emptyset \cup a = a \cup \emptyset = a$$
$$a + b = b + a$$
$$a \cup a = a$$

$(A, \times)$ is a commutative monoid with identity element $[\ ]$:
$$(a \times b) \times c = a \times (b \times c)$$
$$[\ ] \cup a = a \cup [\ ] = a$$

Product left and right distributes over join:
$$a\times(b + c) = (a\times b) + (a\times c)$$
$$(a + b)\times c = (a\times c) + (b\times c)$$

Product by $\emptyset$ annihilates $A$:
$$\emptyset \times a = a \times \emptyset = \emptyset$$

\paragraph{Assumptions}
\subsection{Search Space Construction}

Most \ac{HPO} algorithms are

\subsubsection{Structure of search spaces}


\begin{tabular}{ l | c | c }
Language Feature & Search Space & Parameter Structure \\
\hline
atomic parameters   & one-dim          & single value \\
join                & tree             &              \\
product / operators & multi-dim        & tree         \\
recursion           & infinite tree    &              \\
expression equality & DAG              &              \\
value identity      & ?                & DAG          \\
recursive values    & ?                & ?
\end{tabular}



\subsection{Demands to a good HPO-Algorithm}
A non-exaustive list of general criteria for a good hyperparameter optimization algorithm.

\section{Gaussian Processes Regression}

\subsection{Kernels}

\subsubsection{Squared-Exponential Kernel}
The squared-exponential kernel (also called radial basis function kernel (RBF)) has many desireble properties. For closer points the correlation tends towards one for while the correlation of farer points tends towards one.

\subsubsection{Kernel Combination}
Kernel combination properties. Maybe: Why do they work!

\section{Bayesian Optimization}
What distinguished \ac{HPO} from other non-\ac{HPO}.

\subsection{Aquisition Functions}

\subsubsection{Probability of Improvement}
\subsubsection{Expected Information}

Expected Information (EI) is the most widely used aquistion function. First use was 1998 \cite{jones_efficient_1998}.

$$ \EI(y|x) \coloneqq \int_{-\infty}^{\infty} \max(0, y^*-y)p(y|x)dy $$

For the one-dimensional case a simple closes form formula can be derivated:

$$ \EI(y|x) = \int_{-\infty}^{y^*}(y^*-y)p(y|x)dy$$

$$ = \int_{-\infty}^{y^*}(y^*-y)\normal(y; \mu, \sigma)dy =
\int_{-\infty}^{y^*}(y^*-y)\normal(y-\mu; 0, \sigma)dy$$

$$ = \int_{-\infty}^{y^*}(y^*- t - \mu)\normal(t; 0, \sigma)dt $$

$$ = (y^*-\mu)\int_{-\infty}^{y^*}\normal(t; 0, \sigma)dt - \int_{-\infty}^{y^*}t\cdot\normal(t; 0, \sigma)dt$$

$$ = (y^*-\mu)\Phi(y^*/\sigma) - \phi(y^*/\sigma) $$

Where $\phi$ and $\Phi$ refere to the PDF and CDF of the standart normal distribution.

\subsubsection{Entropy search}
\subsubsection{Upper confidence bound}

\subsection{Aquisition optimization}
The use of a model and an aquisition function leads to a new non-convex optimization problem. Algorithms to find the maximum of the figure of merrit include global optimization technics uschas: DIRECT, L-BFGS-B, ...

\subsubsection{Recommendation Strategy}
The need for a recommendation strategy arises for noisy objective functions. In the deterministic setting the maximal aquisition value becomes the recommendation for the next evaluation step. For non-deterministic aquisition function one needs to generate a sample from a distribution over aquisition values. Strategies like returning the maximum observed value or returning the optimal latent posterior mean can be encountered. Different objective function can require different strategies \cite{hoffman_modular_2014}. 

\subsection{SMBO}
Sequential model-based optimization is a very general algorithmic pattern for global optimization with aquistion functions.





\subsection{Conditional Parameters}


\subsubsection{SMAC}


\subsubsection{The Tree-Parzen Algorithm}
The Tree-Parzen Algorithm \cite{bergstra_algorithms_2011} is a Bayesian-Optimization algorithm for tree-structured parameter spaces.

\subsection{Tree and Graph Kernels/Metrics}


\section{The Tree Farm Algorithm}
Presenting my algorithm for Bayesian optimization of Grammar-Based search spaces.

\subsection{Extention to DAG-structured search spaces}
Identifying equivalent function trees with computer algebra systems.

\subsection{Parallelization}
Simple trick to extend algorithm to parrallel execution.

\subsection{Integration with Manual Search}
Manual guidance before and during the optimization process.

\subsubsection{Prior Information}
In machine learning preknowledge about the learning task can be consindered as choice and distribution over the hypothesis space. This is determined rather indirect by the choice of the \ac{ML}-algorithm and its hyperparameters (or distribution over hyperparameters) or in Bayesian method directly expressed via prior probabilities. Since gaussian processes regession is used here, the choice of the kernel
Prior infotmation can for example be an actual probabilistic prior over the search space. For random sampling this probability can just be used as the sampling probability. For model-based methods, which have no direct sampling, this probability can be interpreted as \textit{probability of improvement} or (more plausible) as \textit{probability of optimum}.

\subsubsection{Search Hints}
A concept I labeled \textit{search hints} is a way to express external knowledge about the search space. I contranst to regular prior knowledge search hits can also be injected into search process on the fly. Intuitively a search hint just denotes good region to search. And once again it is not obvious how to translate this human instructions into the search process.
The easier part is to construct a probability distribution only from hints. If a hint is interpreted as a sample from the space of the probability of optimum then distribution estimation methods like Parzen-Window can be used. If one takes a squard exponential kernel, a hint translates to good region. To indicate better regions one would need to give multiple of samples from the same region, which is unfavourable. To solve this one could give weighted hints. Once again there are different ways to do this.
First one could assign the probability of optimium directly to a region. This however is hard to conceptualize for users and requires not to violate the normalization property (sum of hints must not excede one).
A second way is to allow values between zero and one, fit a curve, and normlize aferwards to get a probability of optimum. Which is much better, because a value of zero keeps the interpretation of zero probability and one get the interpretation of maximum probability. If one allows arbitrary big values for hints the down scaling of former hints could become easier. If one allows also negative values, and includes adding the absolute value of the smalles negative value to all hints, upscaling of former hints would become possible. In both extensions however one looses the interpretation of one and zero.
The third method interpretes hints as a modification of an already existing model.
In an active learning setting point hints can be handeled without an model modification, by simply forcing this hints into the processing queue.

intuitive way to do this is ascribing an increase in probability to positive hints and and decrease in probability to negative hints.

\paragraph{Credebility and Authority}
The \textit{credebility factor} or \textit{authority factor} is a way to ...

\subsection{Objective Function Approximation}


\section{Implementation}
\subsection{Search Space Construction DSL}
The search space construction system has atomic spaces that can
be combined to construct more complex spaces.

\subsubsection{Atomic Spaces}
Atomic spaces cannot (as the name suggest)

\paragraph{Categorical}
Categoriacal parameters have a finite unstructured domain of numerical or non-numerical values. This type is used for nominal scaled parameters like labels in a classification problem, basis-functions in linear regression or different activation functions in feedforward neural networks.

\paragraph{Continuous}
Continues parametes are bounded or un-bounded intervals over the real numbers. The simplest way to construct them is by slicing wich represents the real numbers.

\begin{minted}{python}
from treefarm import *

p1 = R[0:]

inter = Intervall(sub=0, sub=float('inf'))
p2 = to_space(inter)

\end{minted}


\paragraph{Discrete}



\subsubsection{Combinators}

\subsubsection{Functions}

\subsubsection{Operators}

\subsection{Function Graph Simplification}


\subsection{Algorithm Templates}


\section{Experiments}



\subsection{Gaussian Process Regression}
\subsubsection{Kernel Combination Optimization}
\subsubsection{Kernel Parameter and Kernel Combination Optimization}
\subsection{Elastic Net Linear Regression}
\subsection{Feat-Forward Networks}

\section{Conclusion}

\section{Outlook}
\paragraph{Connection to Functional Programming}
\paragraph{Connection to Constraint Satisfaction Problems}
\paragraph{Connection to Probabilistic Programming}
\paragraph{Connection to Reinforcement Learning}
\paragraph{Integration with Workflow-Managers}


\printbibliography


\end{document}
