\documentclass[english]{article}
\usepackage[utf8]{inputenc}
%\usepackage{babel}
\usepackage[backend=bibtex]{biblatex}
\usepackage{hyperref}
\usepackage{mathtools}
\usepackage[printonlyused]{acronym}
\usepackage{minted}
\usepackage{amsthm}


\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

\bibliography{library.bib}

% Add mathematical foo
\newcommand{\EI}{\operatorname{EI}}
\newcommand{\normal}{\mathcal{N}}

\begin{document}

\title{Bayesian Hyperparameter-Optimization in Grammer-Based Search Spaces}
\author{Moritz Meier}
\maketitle
\tableofcontents
\newpage

\section*{List of Acronyms}
  \begin{acronym}
  \acro{AI}{artificial intelligence}
  \acro{BO}{Bayesian Optimization}
  \acro{BOA}{Bayesian optimization algorithm}
  \acro{BGO}{Bayesian global optimization}
  \acro{DAG}{directed acyclic graph}
  \acro{EGO}{efficient global optimization}
  \acro{GO}{global optimization}
  \acro{HPO}{hyperparameter optimization}
  \acro{IAF}{information acquisition function}
  \acro{ML}{machine learning}
  \acro{SMAC}{sequential model-based algorithm configuration}
  \acro{SMBO}{sequential model-based optimization}
\end{acronym}

\section{Introduction}
Mathematical Programming
Metaheuristics
Programm Configuration
Learning \& Optimizaion.


\section{Global Black-Box Optimization}

\subsection{Distinctions}

\subsubsection*{gradient based vs. derivative free}
also

\subsubsection*{local vs. global}

\subsubsection*{model-based vs. instance-based}
More sophisticated \ac{GO} algorithms can be devided into

The use of stochastic processe in \ac{GO} for surrogate fitting is called \ac{BO}. This approach was first explored by Harold Kushner in 1964 \cite{kushner_new_1964}. In \cite{jones_efficient_1998} the surrogate is also called \textit{figure of merrit}.


\subsection{Active Learning}


\subsection{Bandit Problem}
 continuum-armed bandit problem


\section{Hyperparameter Optimization}


\subsection{Machine Learning as Optimization}

Most problems in \ac{AI} and \ac{ML} can be expressed) as
optimization problems.

 - Types and Error Functions
 - Model Selection

\begin{quote}
Machine learning algorithms, however, have certain characteristics that distinguish them from other black-box optimization problems.  First, each function evaluation can require a variable amount of time:  training a small neural network with 10 hidden units will take less time than a bigger net-work with 1000 hidden units.  Even without considering duration, the advent of cloud computing makes it possible to quantify economically the cost of requiring large-memory machines for learning, changing the actual cost in dollars of an experiment with a different number of hidden units.
\end{quote}
Second, machine learning experiment EGO algorithm
 - Categrorical
 - Discrete
 - Continunous


\subsection{Combinators}
Join and prod over parameter-lists form an idempotent semiring:

$(A, \cup)$ is a idempotent commutative monoid (or join-semilatice with zero) with identity element $\emptyset$:
$$(a \cup b) \cup c = a \cup (b \cup c)$$
$$\emptyset \cup a = a \cup \emptyset = a$$
$$a + b = b + a$$
$$a \cup a = a$$

$(A, \times)$ is a commutative monoid with identity element $[\ ]$:
$$(a \times b) \times c = a \times (b \times c)$$
$$[\ ] \cup a = a \cup [\ ] = a$$

Product left and right distributes over join:
$$a\times(b + c) = (a\times b) + (a\times c)$$
$$(a + b)\times c = (a\times c) + (b\times c)$$

Product by $\emptyset$ annihilates $A$:
$$\emptyset \times a = a \times \emptyset = \emptyset$$

\paragraph{Assumptions}
\subsection{Search Space Construction}
\subsubsection{Search Space Hierachy}

\begin{tabular}{ l | c | c }
Language Feature & Search Space & Parameter Structure \\
\hline
atomic parameters   & one-dim          & single value \\
join                & tree             &              \\
product / operators & multi-dim        & tree         \\
recursion           & infinite tree    &              \\
expression equality & DAG              &              \\
value identity      & ?                & DAG          \\
recursive values    & ?                & ?
\end{tabular}



\subsection{Demands to a good HPO-Algorithm}
A non-exaustive list of general criteria for a good hyperparameter optimization algorithm.

\section{Gaussian Processes Regression}

\subsection{Kernels}
\subsubsection{Squared-Exponential Kernel}
The squared-exponential kernel (also called radial basis function kernel (RBF)) has many desireble properties. For closer points the correlation tends towards one for while the correlation of farer points tends towards one.
\subsubsection{Kernel Combination}
Kernel combination properties. Maybe: Why do they work!

\section{Bayesian Optimization}
What distinguished \ac{HPO} from other non-\ac{HPO}.

\subsection{Aquisition Functions}

\subsubsection{Probability of Improvement}
\subsubsection{Expected Information}

Expected Information (EI) is the most widely used aquistion function. First use was 1998 \cite{jones_efficient_1998}.

$$ \EI(y|x) \coloneqq \int_{-\infty}^{\infty} \max(0, y^*-y)p(y|x)dy $$

For the one-dimensional case a simple closes form formula can be derivated:

$$ \EI(y|x) = \int_{-\infty}^{y^*}(y^*-y)p(y|x)dy$$

$$ = \int_{-\infty}^{y^*}(y^*-y)\normal(y; \mu, \sigma)dy =
\int_{-\infty}^{y^*}(y^*-y)\normal(y-\mu; 0, \sigma)dy$$

$$ = \int_{-\infty}^{y^*}(y^*- t - \mu)\normal(t; 0, \sigma)dt $$

$$ = (y^*-\mu)\int_{-\infty}^{y^*}\normal(t; 0, \sigma)dt - \int_{-\infty}^{y^*}t\normal(t; 0, \sigma)dt$$

$$ = (y^*-\mu)\Phi(y^*/\sigma) - \phi(y^*/\sigma) $$

Where $\phi$ and $\Phi$ refere to the PDF and CDF of the standart normal distribution.

\subsubsection{Entropy search}
\subsubsection{Upper confidence bound}

\subsection{SMBO}
Sequential model-based optimization is a very general algorithmic pattern for global optimization with aquistion functions.
\subsection{SMAC}


\subsection{The Tree-Parzen Algorithm}
The Tree-Parzen Algorithm \cite{bergstra_algorithms_2011} is a Bayesian-Optimization algorithm for tree-structured parameter spaces.

\subsection{Tree and Graph Kernels/Metrics}


\section{The Tree Farm Algorithm}
Presenting my algorithm for Bayesian optimization of Grammar-Based search spaces.

\subsection{Extention to DAG-structured search spaces}
Identifying equivalent function trees with computer algebra systems.

\subsection{Parallelization}
Simple trick to extend algorithm to parrallel execution.

\subsection{Integration with Manual Search}
Manual guidance before and during the optimization process.

\subsubsection{Prior Information}
In machine learning preknowledge about the learning task can be consindered as choice and distribution over the hypothesis space. This is determined rather indirect by the choice of the \ac{ML}-algorithm and its hyperparameters (or distribution over hyperparameters) or in Bayesian method directly expressed via prior probabilities. Since gaussian processes regession is used here, the choice of the kernel
Prior infotmation can for example be an actual probabilistic prior over the search space. For random sampling this probability can just be used as the sampling probability. For model-based methods, which have no direct sampling, this probability can be interpreted as \textit{probability of improvement} or (more plausible) as \textit{probability of optimum}.

\subsubsection{Search Hints}
A concept I labeled \textit{search hints} is a way to express external knowledge about the search space. I contranst to regular prior knowledge search hits can also be injected into search process on the fly. Intuitively a search hint just denotes good region to search. And once again it is not obvious how to translate this human instructions into the search process.
The easier part is to construct a probability distribution only from hints. If a hint is interpreted as a sample from the space of the probability of optimum then distribution estimation methods like Parzen-Window can be used. If one takes a squard exponential kernel, a hint translates to good region. To indicate better regions one would need to give multiple of samples from the same region, which is unfavourable. To solve this one could give weighted hints. Once again there are different ways to do this.
First one could assign the probability of optimium directly to a region. This however is hard to conceptualize for users and requires not to violate the normalization property (sum of hints must not excede one).
A second way is to allow values between zero and one, fit a curve, and normlize aferwards to get a probability of optimum. Which is much better, because a value of zero keeps the interpretation of zero probability and one get the interpretation of maximum probability. If one allows arbitrary big values for hints the down scaling of former hints could become easier. If one allows also negative values, and includes adding the absolute value of the smalles negative value to all hints, upscaling of former hints would become possible. In both extensions however one looses the interpretation of one and zero.
The third method interpretes hints as a modification of an already existing model.
In an active learning setting point hints can be handeled without an model modification, by simply forcing this hints into the processing queue.

intuitive way to do this is ascribing an increase in probability to positive hints and and decrease in probability to negative hints.

\paragraph{Credebility and Authority}
The \textit{credebility factor} or \textit{authority factor} is a way to ...

\subsection{Objective Function Approximation}


\section{Implementation}
\subsection{Search Space Construction DSL}
The search space construction system has atomic spaces that can
be combined to construct more complex spaces.

\subsubsection{Atomic Spaces}
Atomic spaces cannot (as the name suggest)

\paragraph{Categorical}
Categoriacal parameters have a finite unstructured domain of numerical or non-numerical values. This type is used for nominal scaled parameters like labels in a classification problem, basis-functions in linear regression or different activation functions in feedforward neural networks.

\paragraph{Continuous}
Continues parametes are bounded or un-bounded intervals over the real numbers. The simplest way to construct them is by slicing wich represents the real numbers.

\begin{minted}{python}
from treefarm import *

p1 = R[0:]

inter = Intervall(sub=0, sub=float('inf'))
p2 = to_space(inter)

\end{minted}


\paragraph{Discrete}



\subsubsection{Combinators}

\subsubsection{Functions}

\subsubsection{Operators}

\subsection{Function Graph Simplification}


\subsection{Algorithm Templates}


\section{Experiments}



\subsection{Gaussian Process Regression}
\subsubsection{Kernel Combination Optimization}
\subsubsection{Kernel Parameter and Kernel Combination Optimization}
\subsection{Elastic Net Linear Regression}
\subsection{Feat-Forward Networks}

\section{Conclusion}

\section{Outlook}
\paragraph{Connection to Functional Programming}
\paragraph{Connection to Constraint Satisfaction Problems}
\paragraph{Connection to Probabilistic Programming}
\paragraph{Connection to Reinforcement Learning}
\paragraph{Integration with Workflow-Managers}


\printbibliography


\end{document}
